p8105\_hw2\_dtw2127
================
Dee Wang

## Problem 1

``` r
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(tidyverse)
library(lubridate)
library(ggplot2)
```

We will read in and clean the “Mr. Trash Wheel” sheet. We’ll skip the
first row as it has a graphic, clean up the variable names, omit rows
with missing data and round the sports balls values to the nearest
integer.

``` r
mrtrash_data = read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "Mr. Trash Wheel", skip = 1) %>% #specify sheet to read in and skip row with graphic 
  janitor::clean_names() %>%
  select(dumpster:homes_powered) %>% #omit non-data entries
  drop_na() %>% # omit rows without dumpster-specific data (drop rows with missing data)
  mutate(sports_balls = round(sports_balls)) #round sports balls number to nearest integer
```

    ## New names:
    ## * `` -> ...15
    ## * `` -> ...16
    ## * `` -> ...17

Next, we’ll read and clean precipitation data for 2018 and 2019.

``` r
precip_2018 =
  read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "2018 Precipitation", skip = 1) %>% 
  drop_na() %>% #drop rows with missing data 
  mutate(year = 2018) #add year variable 
 
precip_2019 =
  read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "2019 Precipitation", skip = 1) %>% 
  drop_na() %>% #drop rows with missing data 
  mutate(year = 2019) #add year variable 
```

Next we will combine the precipitation datasets and convert month to a
character variable.

``` r
precip_combined = bind_rows(precip_2018, precip_2019) %>% #combine precipitation datasets
  mutate(Month = month.name[Month]) #convert month to character variable  
```

The Mr. Trash Wheel dataset has 453 observations and 14 variables for
the years 2014 to 2021. The dataset includes information on dumpster
number, date of collection, weight and volume of litter, as well as how
many homes are powered by the trash incinerated, among other variables.

There are 12 complete observations in the 2018 Precipitation Dataset,
and 12 complete observations in the 2019 Precipitation Dataset. The
combined dataset has 24 observations.The 2018 Precipitation Dataset has
monthly precipitation values for January through December, whereas the
2019 Precipitation Dataset only has monthly precipitation values (in)
for January through June. Average monthly rain fall for 2018 was 5.86,
and 2.83 for the months of January through June in 2019.

The total precipitation in 2018, as calculated with available data, was
70.33.

The median number of sports balls in a dumpster in 2019 was 9

## Problem 2

First, we will import and clean the data in pols-month. We will break up
the ‘mon’ variable into ‘year’, ‘month’ and ‘day’ variables, replace
month number with month name, create a president variable using the
‘gop’ and ‘dem’ variable values and remove the variables ‘prez\_dem’ and
‘prez\_gop’, and remove the ‘day’ variable.

``` r
pols_month = read_csv("./data/pols-month.csv") %>% 
  separate(mon, into = c("Year", "Month", "Day"), sep = "-") %>%
  mutate(Month = as.numeric(Month)) %>% 
  mutate(Month = month.name[Month]) %>% 
  pivot_longer(c(prez_gop,prez_dem), names_prefix = "prez_", names_to = "President") %>% 
  filter(value > 0) %>%
  select(-Day, -value) %>% #remove day variable 
  mutate(Year = as.numeric(Year))
```

    ## Rows: 822 Columns: 9

    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon

    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#note -- value of 2 indicates Ford assuming presidency.
```

Next, we will clean the snp dataset similarly to how we cleaned the
pols-month dataset. We will replace arrange the dataset according to
year and month and will have year and month as the leading columns.

``` r
snp <- read_csv("./data/snp.csv") %>% 
  mutate(date = lubridate::mdy(date)) %>% 
  separate(date, into = c("Year", "Month", "Day")) %>% 
  mutate(Year = as.numeric(Year)) %>% 
  mutate(Year = ifelse(Year > 2021, Year - 100, Year)) %>%
  mutate(Month = as.numeric(Month)) %>%
  mutate(Month = month.name[Month]) %>%
  arrange(Year, Month) 
```

    ## Rows: 787 Columns: 2

    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close

    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

Next, we will tidy the unemployment data so that we can merge it with
the previous datasets. To ensure that the ‘Month’ variable is consistent
with the pols-month and snp datasets, we will convert the abbreviated
names to a numeric form, and then convert the numeric form to character
using month.name.

``` r
unemployment = read_csv("./data/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "Month",
    values_to = "Unemployment (%)" 
  ) %>% 
  mutate(Month = match(Month, month.abb)) %>% 
  mutate(Month = month.name[Month])
```

    ## Rows: 68 Columns: 13

    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec

    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

We’ll merge snp into pols, and then merge unemployment using left joins.

``` r
pols_snp = left_join(pols_month, snp, by = c("Year", "Month"))

pols_snp_unemployment = left_join(pols_snp, unemployment, by = c("Year", "Month"))
```

The original ‘pols’ dataset consisted of 822 rows, and 9 columns. The
dataset has information related to the number of democratic and
republican national politicians at a given time, for the years 1947 to
2015.

The original ‘snp’ dataset contained 787 rows and 2 columns. The dataset
contains information about closing values of the S&P stock index at a
given time, for the years 1950 to 2015.

The original ‘unemployment’ dataset contained 816 and 13 columns. The
dataset contains information about percentage of unemployment at a given
time, for the years 1948 to 2015.

The combined dataset is 822 rows and 12, and contains data from the
years 1947 to 2015. Key variables include month and year, closing value
of the SNP, party affiliation of the president and unemployment
percentage.

## Problem 3

We will load and tidy the ‘popular baby names’ dataset. The Ethnicity
categories are not consistently used. We need to change instances of
“ASIAN AND PACI” to “ASIAN AND PACIFIC ISLANDER”, and “BLACK NON HISP”
to “BLACK NON HISPANIC”, and “WHITE NON HISP” to “WHITE NON HISPANIC”.
We also want the case of the names to be consistent.

``` r
babynames <- read_csv("./data/Popular_Baby_Names.csv") %>% 
  janitor::clean_names() %>% 
  mutate(ethnicity = replace(ethnicity, ethnicity == "BLACK NON HISP", "BLACK NON HISPANIC")
  ) %>% 
  mutate(ethnicity = replace(ethnicity, ethnicity == "WHITE NON HISP", "WHITE NON HISPANIC")
  ) %>% 
  mutate(ethnicity = replace(ethnicity, ethnicity == "ASIAN AND PACI", "ASIAN AND PACIFIC ISLANDER")
  ) %>% 
  mutate(childs_first_name = str_to_title(childs_first_name)) %>%
  distinct() #remove rows that are duplicated
```

    ## Rows: 19418 Columns: 6

    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr (3): Gender, Ethnicity, Child's First Name
    ## dbl (3): Year of Birth, Count, Rank

    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

We’ll create reader-friendly tables showing the rank in popularity of
the name “Olivia” as a female baby name over time.

``` r
popularity_olivia <- babynames %>% 
  filter(childs_first_name == "Olivia") %>% 
  select("ethnicity", "year_of_birth", "rank") %>% 
  pivot_wider(names_from = "year_of_birth",
            values_from = "rank") 

popularity_olivia = popularity_olivia[, c(1,5,4,3,2)] #reorder columns
```

Now we will create a table showing the most popular male baby name over
time.

``` r
popular_male_babyname <- babynames %>% 
  filter(gender == "MALE") %>% 
  select("ethnicity", "year_of_birth", "rank", "childs_first_name") %>% 
  pivot_wider(names_from = "year_of_birth",
              values_from = "childs_first_name") %>% 
  filter(rank == 1) %>% 
  select(-rank)
```

    ## Warning: Values are not uniquely identified; output will contain list-cols.
    ## * Use `values_fn = list` to suppress this warning.
    ## * Use `values_fn = length` to identify where the duplicates arise
    ## * Use `values_fn = {summary_fun}` to summarise duplicates

``` r
popular_male_babyname = popular_male_babyname[, c(1,7,6,5,4,3,2)] #reorder columns
```

Next we’ll create a scatter plot showing number of male, white,
non-hispanic children born in 2016 with a certain name against the rank
in popularity of that name.

``` r
white_male_names_2016 = babynames %>%
  filter(gender == "MALE" & ethnicity == "WHITE NON HISPANIC" & year_of_birth == 2016) %>% 
  select(count, rank)

ggplot(white_male_names_2016, aes(x = count, y = rank)) + 
  geom_point() + 
  labs(x = "number of children with name", 
       y = "rank in popularity of name",
       title = "Frequency of white non-hispanic male baby names against rank in 2016")
```

![](p8105_hw2_dtw2127_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->
